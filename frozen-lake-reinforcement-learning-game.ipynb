{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random as rd","metadata":{"id":"YRvje9iH8VPK","execution":{"iopub.status.busy":"2024-02-01T17:54:16.594643Z","iopub.execute_input":"2024-02-01T17:54:16.595799Z","iopub.status.idle":"2024-02-01T17:54:16.603195Z","shell.execute_reply.started":"2024-02-01T17:54:16.595747Z","shell.execute_reply":"2024-02-01T17:54:16.601405Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"```\nSFFF\nFHFH\nFFFH\nHFFG\n```\n\n","metadata":{"id":"sZCNb1_c8nUk"}},{"cell_type":"markdown","source":"***Frozen lake involves crossing a frozen lake from Start(S) to Goal(G) without falling into any Holes(H) by walking over the Frozen(F) lake. The agent may not always move in the intended direction due to the slippery nature of the frozen lake.***","metadata":{}},{"cell_type":"code","source":"action_map = {0:'left',\n          1:'down',\n          2:'right',\n          3:'up'}","metadata":{"id":"h-7jljF4YDDx","execution":{"iopub.status.busy":"2024-02-01T17:54:17.605505Z","iopub.execute_input":"2024-02-01T17:54:17.606174Z","iopub.status.idle":"2024-02-01T17:54:17.626617Z","shell.execute_reply.started":"2024-02-01T17:54:17.606123Z","shell.execute_reply":"2024-02-01T17:54:17.622418Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Frozen Lake Enviroment","metadata":{}},{"cell_type":"markdown","source":"![Frozen Lake](https://www.gymlibrary.dev/_images/frozen_lake.gif)","metadata":{}},{"cell_type":"code","source":"# The game starts at the S tile. The object of the \n# game is to get to the goal (G) without landing in a hole (H).\n\nclass Env:\n    def __init__(self):\n        self.env = np.array([[0,0,0,0],\n                            [0,-1,0,-1],\n                            [0,0,0,-1],\n                            [-1,0,0,2]])\n\n        self.win_reward = 1\n        self.loss_reward = 0\n\n        self.current_state = (0,0)\n        self.shape = self.env.shape\n        self.done = False\n        self.reward = 0\n\n    def terminate_state(self):\n        row,col = self.current_state\n        if self.env[row][col] == 2:\n            self.done = True\n            self.reward = self.win_reward\n\n        elif self.env[row][col] == -1:\n            self.done = True\n            self.reward = self.loss_reward\n\n        else:\n            self.done = False\n            self.reward = 0\n\n    def step(self,action):\n        row,col = self.current_state\n        if action == 2:\n            if col+1 < self.shape[1]:\n                self.current_state = (row,col+1)\n        if action == 0:\n            if col-1 >= 0:\n                self.current_state = (row,col-1)\n        if action == 1:\n            if row-1 >= 0:\n                self.current_state = (row-1,col)\n        if action == 3:\n            if row+1 < self.shape[0]:\n                self.current_state = (row+1,col)\n\n        self.terminate_state()\n        return self.current_state , self.done , self.reward\n\n\n    def render(self):\n        row,col = self.env.shape\n        env_rend = ''\n        for i in range(row):\n            for j in range(col):\n                state = self.env[i][j]\n                if self.current_state == (i,j):\n                    env_rend += 'S'\n                elif state == 0:\n                    env_rend += 'F'\n                elif state == -1:\n                    env_rend += 'H'\n                else:\n                    env_rend += 'G'\n            env_rend += '\\n'\n        print(env_rend)","metadata":{"id":"L4yLZZAX8ZfR","execution":{"iopub.status.busy":"2024-02-01T18:14:32.200019Z","iopub.execute_input":"2024-02-01T18:14:32.200416Z","iopub.status.idle":"2024-02-01T18:14:32.217682Z","shell.execute_reply.started":"2024-02-01T18:14:32.200388Z","shell.execute_reply":"2024-02-01T18:14:32.216568Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"env = Env()\nobs,done,reward = env.step(2)\nprint(f'observation : {obs} done : {done} reward : {reward}')\n\n# we can print the environment if we want to look at it\n# with a current state S\nenv.render()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sBvd86pw_cYz","outputId":"8205c158-d0f9-45f7-a6f1-b6d95e3f71d8","execution":{"iopub.status.busy":"2024-02-01T18:14:32.649737Z","iopub.execute_input":"2024-02-01T18:14:32.650128Z","iopub.status.idle":"2024-02-01T18:14:32.656842Z","shell.execute_reply.started":"2024-02-01T18:14:32.650099Z","shell.execute_reply":"2024-02-01T18:14:32.655929Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"observation : (0, 1) done : False reward : 0\nFSFF\nFHFH\nFFFH\nHFFG\n\n","output_type":"stream"}]},{"cell_type":"code","source":"done = False\nenv = Env()\nactions = [0,1,2,3]\nwhile not done:\n    action = rd.choice(actions)\n    obs,done,reward = env.step(action)\n    print(f'observation : {obs} done : {done} reward : {reward} action : {action_map[action]}')\n    env.render()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IcvDzeyf883u","outputId":"7722ddd3-bc52-406a-a660-9bf81bd52a24","execution":{"iopub.status.busy":"2024-02-01T18:14:32.918583Z","iopub.execute_input":"2024-02-01T18:14:32.919301Z","iopub.status.idle":"2024-02-01T18:14:32.927019Z","shell.execute_reply.started":"2024-02-01T18:14:32.919254Z","shell.execute_reply":"2024-02-01T18:14:32.925546Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"observation : (1, 0) done : False reward : 0 action : up\nFFFF\nSHFH\nFFFH\nHFFG\n\nobservation : (0, 0) done : False reward : 0 action : down\nSFFF\nFHFH\nFFFH\nHFFG\n\nobservation : (1, 0) done : False reward : 0 action : up\nFFFF\nSHFH\nFFFH\nHFFG\n\nobservation : (1, 0) done : False reward : 0 action : left\nFFFF\nSHFH\nFFFH\nHFFG\n\nobservation : (2, 0) done : False reward : 0 action : up\nFFFF\nFHFH\nSFFH\nHFFG\n\nobservation : (3, 0) done : True reward : 0 action : up\nFFFF\nFHFH\nFFFH\nSFFG\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Collection","metadata":{"id":"Vh2x6I10Ydp3"}},{"cell_type":"code","source":"import random as rd\nfrom tqdm import tqdm\n\nenv = Env()\nnum_episodes = 50000\nlife_memory = []\nactions = [0,2,3]\ntotal_win = 0\n\nfor i in tqdm(range(num_episodes)):\n    env = Env()\n    done = False\n    ep_memory = []\n    total_reward = 0\n    old_obs = (0,0)\n    while not done:\n        new_action = rd.choice(actions)\n        obs,done,reward = env.step(new_action)\n        total_reward += reward\n        ep_memory.append({\n            \"row\": old_obs[0],\n            \"col\":old_obs[1],\n            \"action\": new_action,\n            \"reward\": reward,\n            \"episode\": i,\n        })\n        old_obs = obs\n\n    if total_reward > 0:\n        total_win+=1\n\n    # incorporate total reward\n    num_steps = len(ep_memory)\n    for i, ep_mem in enumerate(ep_memory):\n        ep_mem[\"tot_reward\"] = total_reward\n        ep_mem[\"decay_reward\"] = i*total_reward/num_steps\n    life_memory.extend(ep_memory)\n\nprint(f'\\nwin : {total_win*100/num_episodes}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"20Ee6Ei38-3A","outputId":"e7f2d345-3e63-4016-e870-cdd056324a34","execution":{"iopub.status.busy":"2024-02-01T18:14:33.318928Z","iopub.execute_input":"2024-02-01T18:14:33.319318Z","iopub.status.idle":"2024-02-01T18:14:35.564028Z","shell.execute_reply.started":"2024-02-01T18:14:33.319290Z","shell.execute_reply":"2024-02-01T18:14:35.562783Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"100%|██████████| 50000/50000 [00:02<00:00, 22428.95it/s]","output_type":"stream"},{"name":"stdout","text":"\nwin : 5.02\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Convert to DataFrame","metadata":{"id":"a-t5LSqNhaRq"}},{"cell_type":"code","source":"memory_df = pd.DataFrame(life_memory)","metadata":{"id":"F6A87H5UePvU","execution":{"iopub.status.busy":"2024-02-01T18:14:35.566458Z","iopub.execute_input":"2024-02-01T18:14:35.566938Z","iopub.status.idle":"2024-02-01T18:14:36.711198Z","shell.execute_reply.started":"2024-02-01T18:14:35.566898Z","shell.execute_reply":"2024-02-01T18:14:36.709969Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"memory_df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ArIws-BbeyVU","outputId":"7a31d1a5-eb53-43af-c9c7-4859972909c5","execution":{"iopub.status.busy":"2024-02-01T18:14:36.713336Z","iopub.execute_input":"2024-02-01T18:14:36.713858Z","iopub.status.idle":"2024-02-01T18:14:36.730001Z","shell.execute_reply.started":"2024-02-01T18:14:36.713815Z","shell.execute_reply":"2024-02-01T18:14:36.728434Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"   row  col  action  reward  episode  tot_reward  decay_reward\n0    0    0       3       0        0           0           0.0\n1    1    0       3       0        0           0           0.0\n2    2    0       3       0        0           0           0.0\n3    0    0       3       0        1           0           0.0\n4    1    0       2       0        1           0           0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row</th>\n      <th>col</th>\n      <th>action</th>\n      <th>reward</th>\n      <th>episode</th>\n      <th>tot_reward</th>\n      <th>decay_reward</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Display First 5 episode which has win state","metadata":{"id":"4fS4VzjNhyIl"}},{"cell_type":"code","source":"memory_df[memory_df['reward'] == 1]['episode'].head()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JUdTyyR2hJGg","outputId":"1abe49ce-6b38-4939-ffc8-b58b3aaac29b","execution":{"iopub.status.busy":"2024-02-01T18:14:51.130756Z","iopub.execute_input":"2024-02-01T18:14:51.131154Z","iopub.status.idle":"2024-02-01T18:14:51.141216Z","shell.execute_reply.started":"2024-02-01T18:14:51.131124Z","shell.execute_reply":"2024-02-01T18:14:51.140126Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"19      3\n287    56\n295    57\n332    62\n371    65\nName: episode, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"memory_df[memory_df['episode'] == 3]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"XdgbgWRhfNqy","outputId":"7f180d3f-238f-44a0-f1ff-a33125f6e639","execution":{"iopub.status.busy":"2024-02-01T18:14:55.730218Z","iopub.execute_input":"2024-02-01T18:14:55.730606Z","iopub.status.idle":"2024-02-01T18:14:55.746655Z","shell.execute_reply.started":"2024-02-01T18:14:55.730577Z","shell.execute_reply":"2024-02-01T18:14:55.745534Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"    row  col  action  reward  episode  tot_reward  decay_reward\n11    0    0       3       0        3           1      0.000000\n12    1    0       0       0        3           1      0.111111\n13    1    0       0       0        3           1      0.222222\n14    1    0       3       0        3           1      0.333333\n15    2    0       2       0        3           1      0.444444\n16    2    1       2       0        3           1      0.555556\n17    2    2       3       0        3           1      0.666667\n18    3    2       3       0        3           1      0.777778\n19    3    2       2       1        3           1      0.888889","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row</th>\n      <th>col</th>\n      <th>action</th>\n      <th>reward</th>\n      <th>episode</th>\n      <th>tot_reward</th>\n      <th>decay_reward</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.111111</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.222222</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.444444</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.555556</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.777778</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.888889</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"memory_df.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WaIBs_GXp3WC","outputId":"a00562fb-6258-4836-d54c-78b0b44f8216","execution":{"iopub.status.busy":"2024-02-01T18:15:01.658338Z","iopub.execute_input":"2024-02-01T18:15:01.658759Z","iopub.status.idle":"2024-02-01T18:15:01.666768Z","shell.execute_reply.started":"2024-02-01T18:15:01.658727Z","shell.execute_reply":"2024-02-01T18:15:01.665243Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"(263720, 7)"},"metadata":{}}]},{"cell_type":"code","source":"memory_df.groupby(\"episode\").reward.sum().mean()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eloO7YnufUYb","outputId":"9e6f38cb-b603-4027-9b4e-3fe65985ffbd","execution":{"iopub.status.busy":"2024-02-01T18:15:04.158438Z","iopub.execute_input":"2024-02-01T18:15:04.158862Z","iopub.status.idle":"2024-02-01T18:15:04.180439Z","shell.execute_reply.started":"2024-02-01T18:15:04.158830Z","shell.execute_reply":"2024-02-01T18:15:04.178622Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"0.0502"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model Training","metadata":{"id":"Bn4uVlS9kd2m"}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\ndef warn(*args, **kwargs):\n    return None\n\nwarnings.warn = warn","metadata":{"id":"0K35MUCfmCm6","execution":{"iopub.status.busy":"2024-02-01T18:15:09.818265Z","iopub.execute_input":"2024-02-01T18:15:09.818693Z","iopub.status.idle":"2024-02-01T18:15:09.826036Z","shell.execute_reply.started":"2024-02-01T18:15:09.818661Z","shell.execute_reply":"2024-02-01T18:15:09.824681Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\nfrom sklearn.svm import SVR\n\nmodel = ExtraTreesRegressor(n_estimators=50)\n\n# model = SVR()\ny = 0.5*memory_df.reward + 0.1*memory_df.decay_reward + memory_df.tot_reward\nx = memory_df[[\"row\",\"col\", \"action\"]]\nmodel.fit(x, y)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"W00GLJqmieno","outputId":"5694272e-6998-4c41-94da-67a973a7ed1d","execution":{"iopub.status.busy":"2024-02-01T18:15:12.058836Z","iopub.execute_input":"2024-02-01T18:15:12.059223Z","iopub.status.idle":"2024-02-01T18:15:14.288272Z","shell.execute_reply.started":"2024-02-01T18:15:12.059194Z","shell.execute_reply":"2024-02-01T18:15:14.286933Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"ExtraTreesRegressor(n_estimators=50)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesRegressor(n_estimators=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesRegressor</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesRegressor(n_estimators=50)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Reinforcement Learning Testing ","metadata":{}},{"cell_type":"code","source":"env = Env()\ndone = False\ntest_episode = 500\nstate = (0,0)\ntotal_reward = 0\nenv.current_state = state\nrandom_per = 0.5\nup_action_only = {0:0,1:2,2:3}\n\nfor i in range(test_episode):\n    while not done:\n        random = rd.random()\n        if random < random_per:\n            rl_action = rd.choice(actions)\n        else:\n            input_actions = [[state[0],state[1],i] for i in actions]\n            reward_prob = model.predict(input_actions)\n            rl_action = np.argmax(reward_prob)\n            rl_action = up_action_only[rl_action]\n\n        obs,done,reward = env.step(rl_action)\n        total_reward += reward\nprint(f'score : {total_reward*100/test_episode}')","metadata":{"execution":{"iopub.status.busy":"2024-02-01T18:18:23.221442Z","iopub.execute_input":"2024-02-01T18:18:23.222688Z","iopub.status.idle":"2024-02-01T18:18:23.266040Z","shell.execute_reply.started":"2024-02-01T18:18:23.222641Z","shell.execute_reply":"2024-02-01T18:18:23.264695Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"score : 0.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Reinforcement Learning Performing","metadata":{"id":"ymErCAJ6sr5X"}},{"cell_type":"code","source":"env = Env()\ndone = False\nstate = (0,0)\nenv.current_state = state\nrandom_per = 0.5\nenv.render()\n\nup_action_only = {0:0,1:2,2:3}\n\nwhile not done:\n    random = rd.random()\n    if random < random_per:\n        rl_action = rd.choice(actions)\n    else:\n        input_actions = [[state[0],state[1],i] for i in actions]\n        reward_prob = model.predict(input_actions)\n        rl_action = np.argmax(reward_prob)\n        rl_action = up_action_only[rl_action]\n        \n    obs,done,reward = env.step(rl_action)\n    print(f'action : {action_map[rl_action]}')\n    env.render()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CslEbkbMjDE1","outputId":"11df763a-6ff1-4449-e1e8-bd344a7a8e29"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":"SFFF\n\nFHFH\n\nFFFH\n\nHFFG\n\n\n\naction : up\n\nFFFF\n\nSHFH\n\nFFFH\n\nHFFG\n\n\n\naction : up\n\nFFFF\n\nFHFH\n\nSFFH\n\nHFFG\n\n\n\naction : left\n\nFFFF\n\nFHFH\n\nSFFH\n\nHFFG\n\n\n\naction : right\n\nFFFF\n\nFHFH\n\nFSFH\n\nHFFG\n\n\n\naction : left\n\nFFFF\n\nFHFH\n\nSFFH\n\nHFFG\n\n\n\naction : right\n\nFFFF\n\nFHFH\n\nFSFH\n\nHFFG\n\n\n\naction : up\n\nFFFF\n\nFHFH\n\nFFFH\n\nHSFG\n\n\n\naction : up\n\nFFFF\n\nFHFH\n\nFFFH\n\nHSFG\n\n\n\naction : up\n\nFFFF\n\nFHFH\n\nFFFH\n\nHSFG\n\n\n\naction : up\n\nFFFF\n\nFHFH\n\nFFFH\n\nHSFG\n\n\n\naction : up\n\nFFFF\n\nFHFH\n\nFFFH\n\nHSFG\n\n\n\naction : right\n\nFFFF\n\nFHFH\n\nFFFH\n\nHFSG\n\n\n\naction : up\n\nFFFF\n\nFHFH\n\nFFFH\n\nHFSG\n\n\n\naction : up\n\nFFFF\n\nFHFH\n\nFFFH\n\nHFSG\n\n\n\naction : right\n\nFFFF\n\nFHFH\n\nFFFH\n\nHFFS\n\n\n"}]}]}